# ================================================================
# REQUIREMENTS.TXT - Qwen2-VL Server & Client
# Optimizado para Tesla T4 con 16GB VRAM
# ================================================================

# PyTorch y dependencias CUDA (para servidor)
torch>=2.0.0
torchvision>=0.15.0
torchaudio>=2.0.0

# Transformers y modelo
transformers>=4.37.0
accelerate>=0.20.0
bitsandbytes>=0.41.0

# Procesamiento de imágenes
Pillow>=9.0.0
opencv-python>=4.8.0

# Servidor web (Flask)
Flask>=2.3.0
Werkzeug>=2.3.0

# Cliente HTTP
requests>=2.28.0
urllib3>=1.26.0

# Utilidades generales
numpy>=1.24.0
scipy>=1.10.0

# Manejo de archivos y datos
matplotlib>=3.7.0
seaborn>=0.12.0

# Logging y debugging
tqdm>=4.65.0
psutil>=5.9.0

# Seguridad y validación
safetensors>=0.3.0
huggingface-hub>=0.15.0

# Opcional: para análisis avanzado
pandas>=2.0.0
jsonlines>=3.1.0

# Opcional: para optimización de memoria
pynvml>=11.5.0
py3nvml>=0.2.7

# ================================================================
# NOTAS DE INSTALACIÓN:
#
# Para SERVIDOR con GPU Tesla T4:
# pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
# pip install -r requirements.txt
#
# Para CLIENTE (sin GPU):
# pip install requests pillow flask numpy
#
# Verificar instalación:
# python -c "import torch; print(torch.cuda.is_available())"
# ================================================================
