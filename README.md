# ğŸš€ TFM: EspecializaciÃ³n de LLMs mediante Adapters LoRA

## ğŸ“˜ DescripciÃ³n

Este proyecto, desarrollado como Trabajo de Fin de MÃ¡ster (TFM) por AdriÃ¡n GosÃ¡lvez, implementa un sistema de especializaciÃ³n de modelos de lenguaje de gran escala utilizando tÃ©cnicas de Parameter-Efficient Fine-Tuning (PEFT) mediante LoRA (Low-Rank Adaptation). El sistema procesa documentos de un dominio concreto multimodales y entrena adapters especializados sobre el modelo base PHI4-mini-instruct.

## âœ¨ CaracterÃ­sticas Principales

- ğŸ§  Procesamiento multimodal con Docling para extracciÃ³n de documentos acadÃ©micos
- ğŸ› ï¸ Entrenamiento eficiente mediante LoRA con reducciÃ³n del 99.9% de parÃ¡metros entrenables
- ğŸ§¾ EspecializaciÃ³n de dominio para conocimiento especÃ­fico de papers acadÃ©micos
- âš™ï¸ Optimizado para recursos limitados (GPU T4, 16GB VRAM)
- ğŸ“ˆ Pipeline completo desde extracciÃ³n de datos hasta inferencia especializada
- ğŸŒ **Servidor API REST** para procesamiento de imÃ¡genes con Qwen2-VL
- ğŸ **Cliente Python** para interacciÃ³n con la API

## ğŸ§° Requisitos del Sistema

- **Hardware**: GPU con mÃ­nimo 8GB VRAM (probado en T4)
- **Software**: Python 3.8+, CUDA 11.8+
- **Dependencias principales**: transformers, peft, torch, docling, flask
- **ConfiguraciÃ³n de pruebas**: 32GB RAM, 8 cores CPU, Tesla T4 (16GB VRAM)

## ğŸ—‚ï¸ Estructura del Proyecto

```bash
tfm-lora-specialized-adapter/
â”œâ”€â”€ apps/
â”‚   â””â”€â”€ procesado-imagenes/        # Servidor API REST para anÃ¡lisis de imÃ¡genes
â”‚       â”œâ”€â”€ setup.py              # ConfiguraciÃ³n del modelo Qwen2-VL
â”‚       â”œâ”€â”€ server.py             # Servidor Flask con API REST
â”‚       â”œâ”€â”€ client.py             # Cliente Python para la API
â”‚       â””â”€â”€ requirements.txt      # Dependencias del servidor
â”œâ”€â”€ data/                          # Datasets y datos procesados
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train.sh                  # Script de entrenamiento
â”‚   â””â”€â”€ inference.py              # Script de inferencia
â”œâ”€â”€ models/
â”‚   â””â”€â”€ lora_adapters/            # Adapters LoRA entrenados
â”‚       â”œâ”€â”€ adapter_config.json   # ConfiguraciÃ³n del adapter
â”‚       â””â”€â”€ adapter_model.safetensors # Pesos del adapter (~10MB)
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ dataset_config.json       # ConfiguraciÃ³n del dataset para LoRA
â”‚   â”œâ”€â”€ tokenizer_config.json     # ConfiguraciÃ³n del tokenizer
â”‚   â””â”€â”€ special_tokens_map.json   # Mapeo de tokens especiales
â”œâ”€â”€ results/
â”‚   â””â”€â”€ training_logs/             # Logs y mÃ©tricas de entrenamiento
â”‚       â”œâ”€â”€ trainer_log.jsonl     # Log detallado del entrenamiento
â”‚       â”œâ”€â”€ trainer_state.json    # Estado final del entrenador
â”‚       â”œâ”€â”€ train_results.json    # Resultados de entrenamiento
â”‚       â””â”€â”€ all_results.json      # MÃ©tricas completas
â”œâ”€â”€ dependencies/                   # Framework y dependencias
â”‚   â”œâ”€â”€ llamafactory_setup.md     # ConfiguraciÃ³n LlamaFactory
â”‚   â””â”€â”€ requirements_llamafactory.txt # Dependencias especÃ­ficas
â””â”€â”€ README.md
```

## âš¡ Uso RÃ¡pido

### ğŸ”§ 1. ConfiguraciÃ³n del entorno

```bash
# Instalar LlamaFactory framework
dependencies/llamafactory_setup.md
# Incluir dataset a entrenar
# Ajustar configuraciÃ³n en scripts/train.sh
```

### ğŸ‹ï¸â€â™‚ï¸ 2. Entrenamiento del Adapter

```bash
cd scripts
chmod +x train.sh
./train.sh
```

### ğŸ” 3. Inferencia con Adapter Especializado

```bash
cd scripts
python inference.py
```

## ğŸŒ Servidor API REST para Procesamiento de ImÃ¡genes

El proyecto incluye un servidor API REST basado en Flask que utiliza el modelo Qwen2-VL para anÃ¡lisis de imÃ¡genes con lenguaje natural.

### âš™ï¸ ConfiguraciÃ³n del Servidor

```bash
cd apps/procesado-imagenes
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
python setup.py
python server.py
```

### ğŸ”Œ Endpoints Disponibles

#### ğŸ–¥ï¸ GET `/` - Interfaz Web

[http://localhost:5000](http://localhost:5000)

#### ğŸ” GET `/status` - Estado del Servidor

```bash
curl http://localhost:5000/status
```

#### ğŸ§ª POST `/analyze` - AnÃ¡lisis de Imagen (Form-Data)

```bash
curl -X POST http://localhost:5000/analyze \
  -F "image=@ejemplo.jpg" \
  -F "text=Â¿QuÃ© objetos ves en esta imagen?"
```

#### ğŸ§ª POST `/analyze_base64` - AnÃ¡lisis de Imagen (Base64)

```bash
curl -X POST http://localhost:5000/analyze_base64 \
  -H "Content-Type: application/json" \
  -d '{
    "image": "data:image/jpeg;base64,/9j/4AAQ...",
    "text": "Describe esta imagen en detalle"
  }'
```

#### ğŸ’“ GET `/health` - Estado de Salud

```bash
curl http://localhost:5000/health
```

## ğŸ Cliente Python

```bash
python client.py --interactive
python client.py --image foto.jpg --text "Â¿QuÃ© ves?"
python client.py --status
python client.py --server http://192.168.1.100:5000 --interactive
python client.py --batch ./imagenes --questions preguntas.txt
```

## ğŸ§ª ConfiguraciÃ³n Hardware

- **CPU**: 8 cores
- **RAM**: 32GB
- **GPU**: Tesla T4 (16GB VRAM)
- **Sistema**: Ubuntu 20.04+ con CUDA 11.8

### ğŸ”§ Optimizaciones para T4

- CuantizaciÃ³n 8-bit automÃ¡tica
- Timeout extendido
- Redimensionado de imÃ¡genes grandes

## âš™ï¸ ConfiguraciÃ³n TÃ©cnica

### ğŸ”© ParÃ¡metros LoRA

Archivo: `models/lora_adapters/adapter_config.json`

- Rank (r): 128
- Alpha: 256
- Target modules: 4 mÃ³dulos por capa
- Learning rate: 0.0005

### ğŸ“‚ Dataset

Archivo: `config/dataset_config.json`

## ğŸ“Š Resultados

- ReducciÃ³n de parÃ¡metros: de 3.8B a \~234M (6.2%)
- Adapter final: \~10MB
- Tiempo de entrenamiento: 21 minutos (240 steps, 20 epochs)
- Loss: de 2.09 a 0.07
- Velocidad: 2.8 muestras/segundo (T4)

## ğŸ“ˆ MÃ©tricas de Entrenamiento

- Train Loss final: 0.198
- Learning Rate: 0.0005
- FLOPs totales: 1.01e+16
- DuraciÃ³n total: 1,273 segundos (\~21 min)

## ğŸŒ MÃ©tricas del Servidor API

- Tiempo de respuesta: 3â€“8 segundos por imagen
- VRAM usada: 8â€“12GB
- Concurrencia: mÃºltiple
- Formatos: JPG, PNG, BMP, TIFF, GIF

## ğŸ§ª MetodologÃ­a

- ExtracciÃ³n: DocLING sobre documentos acadÃ©micos
- PreparaciÃ³n: estructuraciÃ³n para LoRA
- Entrenamiento: Adapters LoRA con LlamaFactory
- EvaluaciÃ³n: Inferencia y validaciÃ³n del conocimiento

## ğŸ“¦ Archivos No Incluidos

- Checkpoints intermedios (\~8GB)
- Dataset completo original
- Logs extensos (disponibles bajo peticiÃ³n)

## ğŸ§± Frameworks y Dependencias

### ğŸª LlamaFactory

- Repositorio: [https://github.com/hiyouga/LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory)
- Paper: [https://doi.org/10.48550/arXiv.2403.13372](https://doi.org/10.48550/arXiv.2403.13372)

### ğŸ–¼ï¸ Qwen2-VL

- Modelo: Qwen/Qwen2-VL-7B-Instruct
- CuantizaciÃ³n 8-bit para T4

## ğŸ“ Contexto AcadÃ©mico

Trabajo de Fin de MÃ¡ster (TFM) en Inteligencia Artificial, centrado en la democratizaciÃ³n del fine-tuning de LLMs mediante PEFT.

## ğŸªª Licencia

MIT License â€” ver archivo `LICENSE` para mÃ¡s detalles.

## ğŸ‘¤ Autor

Desarrollado por **AdriÃ¡n GosÃ¡lvez** â€” TFM en IA.

Para mÃ¡s informaciÃ³n tÃ©cnica, consultar el cÃ³digo fuente y la documentaciÃ³n asociada.
